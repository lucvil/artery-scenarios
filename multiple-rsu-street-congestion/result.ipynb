{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_file(file_path):\n",
    "    events = []\n",
    "    current_event = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # 行が空でない場合\n",
    "                current_event.append(line)\n",
    "            else:\n",
    "                if current_event:  # 現在のセクションが空でない場合\n",
    "                    events.append(''.join(current_event))  # 行を結合してセクションを追加\n",
    "                    current_event = []\n",
    "\n",
    "        # 最後のセクションを追加（空行で区切られない場合も考慮）\n",
    "        if current_event:\n",
    "            events.append(''.join(current_event))\n",
    "\n",
    "    return events\n",
    "\n",
    "def filter_events_by_search_str(strings, search_strings):\n",
    "    \"\"\"\n",
    "    指定された検索文字列のいずれかを含む文字列だけを抽出する関数。\n",
    "\n",
    "    :param strings: 検索対象の文字列のリスト\n",
    "    :param search_strings: 検索する文字列のリスト\n",
    "    :return: 検索文字列のいずれかを含む文字列のリスト\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    for s in strings:\n",
    "        if any(search in s for search in search_strings):\n",
    "            filtered.append(s)\n",
    "    return filtered\n",
    "\n",
    "def write_events_to_file(sections, output_path):\n",
    "    with open(output_path, 'w') as file:\n",
    "        for section in sections:\n",
    "            file.write(section + '\\n')  # セクションの後に空白行を追加\n",
    "\n",
    "\n",
    "events = process_log_file(\"./results/General-#0.elog\")\n",
    "search_strings = [\n",
    "    \"DEBUG:Sending (inet::physicallayer::RadioFrame)GeoNet packet from (artery::VanetRadio)radio\",\n",
    "    \"DEBUG:Computing whether reception is possible\"\n",
    "]\n",
    "filtered_events = filter_events_by_search_str(events, search_strings)\n",
    "write_events_to_file(filtered_events, \"./results/filtered-General-#0.elog\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_log_file(file_path):\n",
    "    events = []\n",
    "    current_event = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # Check if the line is not empty\n",
    "                current_event.append(line.strip())\n",
    "            else:\n",
    "                if current_event:\n",
    "                    events.append(current_event)\n",
    "                    current_event = []\n",
    "\n",
    "        # Append the last event if it doesn't end with an empty line\n",
    "        if current_event:\n",
    "            events.append(current_event)\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def extract_event_id(event):\n",
    "    first_item = event[0]  # Get the first item from the list\n",
    "    if \"E #\" in first_item:\n",
    "        parts = first_item.split()\n",
    "        for i, part in enumerate(parts):\n",
    "            if part == \"E\":  # Check for the \"E\" token\n",
    "                if i + 2 < len(parts):  # Ensure there's a number after \"E #\"\n",
    "                    return parts[i + 2]  # Return the number following \"E #\"\n",
    "    return None  # Return None if \"E #\" pattern is not found\n",
    "\n",
    "\n",
    "def filter_events_by_strings(events):\n",
    "\n",
    "    search_strings = [\"KF\"]\n",
    "\n",
    "    filtered_events = [event for event in events if any(any(substring in line for substring in search_strings) for line in event)]\n",
    "    return filtered_events\n",
    "\n",
    "def extract_following_events_based_on_occurrences(events, search_string):\n",
    "    results = {}\n",
    "    for i, event in enumerate(events[:]):\n",
    "        # Count occurrences of the search string in the current event\n",
    "        count = sum(search_string in line for line in event)\n",
    "        \n",
    "        if count > 0:\n",
    "            # Extract (count - 1) subsequent events\n",
    "            count -= 1  # Adjust to extract one fewer than the count of occurrences\n",
    "            buffer_log_num = 1 # tranmitterのログからすぐにreceiverのログに行かない可能性があるためバッファを設ける\n",
    "            subsequent_events = events[i+1:i+1+count+buffer_log_num] if i+1+count <= len(events) else events[i+1:]\n",
    "\n",
    "            results[extract_event_id(event)] = {}\n",
    "            results[extract_event_id(event)][\"transmitter_event\"] = event\n",
    "            results[extract_event_id(event)][\"receiver_events\"] = subsequent_events\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_transmitter_id_and_timestamp(log_entries):\n",
    "    transmitter_id = None\n",
    "    startTime = None\n",
    "    endTime = None\n",
    "    transmitter_position = None\n",
    "    for entry in log_entries:\n",
    "        if \"transmitterId =\" in entry:\n",
    "            parts = entry.split(',')\n",
    "            # Extract transmitterId and startTime\n",
    "            for part in parts:\n",
    "                if \"transmitterId\" in part:\n",
    "                    transmitter_id = part.split('=')[-1].strip()\n",
    "                if \"startTime\" in part:\n",
    "                    startTime = part.split('=')[-1].strip()\n",
    "                    startTime = float(startTime)\n",
    "                if \"endTime\" in part:\n",
    "                    endTime = part.split('=')[-1].strip()\n",
    "                    endTime = float(endTime)\n",
    "                \n",
    "                \n",
    "                # Attempt to extract position if available\n",
    "                if \"startPosition =\" in entry:\n",
    "                    # Correctly capture the full coordinates in the tuple format\n",
    "                    transmitter_position = entry.split(\"startPosition =\")[1].split('),')[0].strip() + ')'\n",
    "    return transmitter_id, startTime, endTime, transmitter_position\n",
    "\n",
    "\n",
    "# from multiple receiver logs, extract receiver_id and reception possibility\n",
    "def extract_receiver_id_and_reception_possibility(log_entries_2list):\n",
    "    results = {}\n",
    "    receivable_id_list = []\n",
    "\n",
    "    for log_entries in log_entries_2list:\n",
    "        receiver_id = None\n",
    "        position = None\n",
    "        reception_status = \"possible\"\n",
    "        startTime = None\n",
    "        endTime = None\n",
    "\n",
    "        for entry in log_entries:\n",
    "\n",
    "\n",
    "            if \"receiverId =\" in entry:\n",
    "                # Extract the receiver ID from the entry\n",
    "                receiver_id = entry.split('receiverId =')[-1].split(',')[0].strip()\n",
    "            # Attempt to extract position if available\n",
    "            if \"startPosition =\" in entry:\n",
    "                # Correctly capture the full coordinates in the tuple format\n",
    "                position = entry.split(\"startPosition =\")[1].split('),')[0].strip() + ')'\n",
    "            # Update the reception status based on current entry details\n",
    "            if \"reception is impossible\" in entry:\n",
    "                reception_status = \"impossible\"\n",
    "\n",
    "\n",
    "            # if \"startTime\" in entry:\n",
    "            #     startTime = entry.split('=')[-1].strip()\n",
    "            # if \"endTime\" in entry:\n",
    "            #     endTime = entry.split('=')[-1].strip()\n",
    "\n",
    "        if receiver_id is not None:\n",
    "            results[receiver_id] = {\n",
    "                \"position\": position,\n",
    "                \"reception_status\": reception_status\n",
    "            }\n",
    "\n",
    "            if reception_status == \"possible\":\n",
    "                receivable_id_list.append(int(receiver_id))\n",
    "            \n",
    "    # order by receiver_id\n",
    "    results = dict(sorted(results.items(), key=lambda x: x[0]))\n",
    "    receivable_id_list = sorted(set(receivable_id_list))\n",
    "        \n",
    "    return results, receivable_id_list\n",
    "\n",
    "\n",
    "def extract_paramater_values(events_dict):\n",
    "    for key, value in events_dict.items():\n",
    "        transmitter_id, transmitter_startTime, transmitter_endTime,transmitter_position = extract_transmitter_id_and_timestamp(value[\"transmitter_event\"])\n",
    "        receive_results, receivable_id_list = extract_receiver_id_and_reception_possibility(value[\"receiver_events\"])\n",
    "        events_dict[key][\"transmitter_id\"] = transmitter_id\n",
    "        events_dict[key][\"startTime\"] = transmitter_startTime\n",
    "        events_dict[key][\"endTime\"] = transmitter_endTime\n",
    "        events_dict[key][\"transmitter_position\"] = transmitter_position\n",
    "        events_dict[key][\"receiver_results\"] = receive_results\n",
    "        events_dict[key][\"receivable_id_list\"] = receivable_id_list\n",
    "        events_dict[key][\"receivable_id_count\"] = len(receivable_id_list)\n",
    "\n",
    "        # Remove the transmitter_event and receiver_events keys\n",
    "        events_dict[key].pop(\"transmitter_event\")\n",
    "        events_dict[key].pop(\"receiver_events\")\n",
    "    \n",
    "    return events_dict\n",
    "\n",
    "def ensure_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def split_json_by_transmitter_id(data):\n",
    "    # transmitter_idでデータを分割するための辞書\n",
    "    split_data = defaultdict(dict)\n",
    "\n",
    "    # 各エントリをtransmitter_idごとに分割\n",
    "    for key, entry in data.items():\n",
    "        transmitter_id = entry.get('transmitter_id')\n",
    "        if transmitter_id is not None:\n",
    "            if transmitter_id not in split_data:\n",
    "                split_data[transmitter_id] = {}\n",
    "            split_data[transmitter_id][key] = entry\n",
    "\n",
    "    # transmitter_idごとのデータを辞書に格納\n",
    "    result = {id: entries for id, entries in split_data.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    speed = 80 # km/hour\n",
    "    events = process_log_file(\"./results/filtered-General-#0.elog\")\n",
    "\n",
    "    # # write event.json file\n",
    "    # with open(\"./results/events.json\", 'w') as f:\n",
    "    #     json.dump(events[:1000], f, indent=4)\n",
    "\n",
    "    log_folder_path = \"./results/speed\" + str(speed) + \"/250vehicle/\"\n",
    "    ensure_directory_exists(log_folder_path)\n",
    "    filtered_events_file_path = log_folder_path + \"filtered_events.json\"\n",
    "    # extracted_events_file_path = log_folder_path + \"/extracted_events.json\"\n",
    "    # print(events)\n",
    "\n",
    "    filtered_string = \"DEBUG:Sending (inet::physicallayer::RadioFrame)GeoNet packet\"\n",
    "    filtered_events = extract_following_events_based_on_occurrences(events, filtered_string)\n",
    "  \n",
    "    # # write to the json file\n",
    "    # with open(filtered_events_file_path, 'w') as f:\n",
    "    #     json.dump(filtered_events, f, indent=4)\n",
    "\n",
    "    # Extract transmitterId, startTime, receiverId, and reception possibility\n",
    "    extracted_events = extract_paramater_values(filtered_events)\n",
    "\n",
    "    # if transmitter_id is not 0 , then the event is deleted form the dictionary\n",
    "    split_events = split_json_by_transmitter_id(extracted_events)\n",
    "\n",
    "    for transmitter_id, split_events_item in split_events.items():        \n",
    "        # write to the json file even if the file is empty\n",
    "        ensure_directory_exists(log_folder_path + str(transmitter_id) + \"/\")\n",
    "        with open(log_folder_path + str(transmitter_id) + \"/extracted_events.json\", 'w') as f:\n",
    "            json.dump(split_events_item, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "log_folder_path = \"./results/speed\" + str(70) + \"/300vehicle/\"\n",
    "ensure_directory_exists(log_folder_path)\n",
    "\n",
    "ensure_directory_exists(log_folder_path + str(0) + \"/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
